from __future__ import absolute_import

import pickle
import numpy as np

from nngp import GP, DKL, VIDKL, BNN
from nngp.kernels import RBFKernel

import argparse


def piecewise_nonlinear(x: np.ndarray) -> np.ndarray:
    return np.piecewise(
        x,
        [x < 1, (x >= 1) & (x < 2), x >= 2],
        [
            lambda x: 1 * x**2.5,
            lambda x: 0.5 * x**1.5 - 2,
            lambda x: 1 * np.exp(0.5 * (x - 2)) + 1
        ]
    )


def nonstationary(x: np.ndarray) -> np.ndarray:
    y_smooth = np.sin(0.7 * x) * (np.abs(x) >= 2)
    y_non_smooth = np.sin(10 * x) * np.exp(-np.abs(2 * x)) * (np.abs(x) < 2)
    return y_smooth + y_non_smooth


def measure(fn, X, noise=0.05):
    """
    Generates noisy data using a specified synthetic function at given input point(s).

    Parameters:
    - fn: callable, the synthetic function to use for generating data.
    - X: np.ndarray, the input values at which to evaluate the function.
    - noise: float, the standard deviation of the Gaussian noise to add (default 0.05).

    Returns:
    - y_noisy: np.ndarray, the noisy output values generated by the function.
    """
    # Generate the output values from the function
    y = fn(X)

    # Add Gaussian noise
    y_noisy = y + np.random.normal(0, noise, X.shape)

    return y_noisy


def fit_predict(model_type, X, y, X_new, kernel=RBFKernel, latent_dim=2, **kwargs):
    """
    Initializes and trains a model based on the model_type argument.

    Parameters:
    - model_type: str, the type of the model ('GP', 'DKL', 'BNN', or 'VIDKL')
    - X: array-like, training input data
    - y: array-like, training target data
    - X_new: array-like, new/test inputs
    - latent_dim: int, the latent dimensionality for DKL and VIDKL
    - kernel: base kernel for GP, DKL, and viDKL. Defaults to RBFKernel.
    - **kwargs: additional arguments passed if necessary
    """

    input_dim = X.shape[-1]

    # Initialize the model based on the type
    if model_type == 'GP':
        model = GP(input_dim, kernel, **kwargs)
    elif model_type == 'DKL':
        model = DKL(input_dim, latent_dim, kernel, **kwargs)
    elif model_type == 'VIDKL':
        model = VIDKL(input_dim, latent_dim, kernel, **kwargs)
    elif model_type == 'BNN':
        model = BNN(input_dim, 1, **kwargs)
    else:
        raise ValueError(f"Unsupported model type: {model_type}")

    # Train the model
    if model_type == 'VIDKL':
        model.fit(X, y, num_steps=5000, step_size=5e-3, **kwargs)
    else:
        model.fit(X, y, num_warmup=1000, num_samples=1000, **kwargs)

    posterior_mean, posterior_var = model.predict(X_new)

    return posterior_mean, posterior_var


def active_learning_loop(fn, model_type, X_initial, y_initial, X_candidate,
                         latent_dim=2, noise=0.05, n_steps=30, **kwargs):
    """
    Active learning routine to iteratively improve model predictions by measuring at points of maximum uncertainty.
    """
    X_train = np.copy(X_initial)
    y_train = np.copy(y_initial)
    history = {"posterior_means": [], "posterior_vars": [], "X_selected": [], "y_selected": []}

    for step in range(n_steps):
        posterior_mean, posterior_var = fit_predict(
            model_type, X_train, y_train, X_candidate, latent_dim=latent_dim, **kwargs)
        max_var_idx = np.argmax(posterior_var.squeeze())
        X_next = X_candidate[max_var_idx].reshape(1, -1)
        y_next = measure(fn, X_next, noise=noise)

        X_train = np.vstack((X_train, X_next))
        y_train = np.append(y_train, y_next)

        history["posterior_means"].append(posterior_mean[max_var_idx])
        history["posterior_vars"].append(posterior_var[max_var_idx])
        history["X_selected"].append(X_next)
        history["y_selected"].append(y_next)

        X_candidate = np.delete(X_candidate, max_var_idx, axis=0)

    return history


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Run active learning routine for specified synthetic function and model type.')
    parser.add_argument('function_type', type=str, choices=['piecewise_nonlinear', 'nonstationary'],
                        help='Type of synthetic function to use.')
    parser.add_argument('model_type', type=str, choices=['GP', 'DKL', 'BNN', 'VIDKL'],
                        help='Type of model to use for predictions.')
    parser.add_argument('--seed', type=int, default=None, help='Optional seed for initializing points.')
    args = parser.parse_args()

    np.random.seed(args.seed)

    # Function selection
    if args.function_type == 'nonstationary':
        fn = nonstationary
        X_initial = np.random.uniform(-7, 7, (4, 1))
        y_initial = measure(fn, X_initial)
        X_candidate = np.linspace(-7, 7, 200).reshape(-1, 1)
    elif args.function_type == 'piecewise_nonlinear':
        fn = piecewise_nonlinear
        X_initial = np.random.uniform(0, 3, (4, 1))
        y_initial = measure(fn, X_initial)
        X_candidate = np.linspace(0, 3, 200).reshape(-1, 1)
    else:
        raise ValueError("Unknown function type specified.")

    model_type = args.model_type

    # Proceed with the active learning routine
    history = active_learning_loop(
        fn, model_type, X_initial, y_initial, X_candidate, n_steps=30)
    print("Active learning completed.")

    # Prepare the data to be saved
    save_data = {
        "X_initial": X_initial,
        "y_initial": y_initial,
        "history": history
    }

    # Save data to disc
    filename = f"active_learning_{args.model_type}_seed_{args.seed}.pkl"
    with open(filename, 'wb') as file:
        pickle.dump(save_data, file)
    print(f"Data saved to {filename}.")
